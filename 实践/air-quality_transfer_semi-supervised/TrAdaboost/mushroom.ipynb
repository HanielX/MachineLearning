{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用SVM TrAdaboost(SVM) 等方法复现文章中的精度\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from utils import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "e    4208\n",
       "p    3916\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.read_csv('data/mushrooms.csv')\n",
    "frame['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = frame.columns\n",
    "# label encode 对于每一列\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "for col in frame.columns:\n",
    "    frame[col] = labelencoder.fit_transform(frame[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4208\n",
       "1    3916\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# oneHotEncoder\n",
    "# enc = OneHotEncoder()\n",
    "# X = enc.fit_transform(frame[columns[1:]]).toarray()\n",
    "# y = frame['class'].values\n",
    "# y = np.array([y])\n",
    "# X = np.concatenate((y.T,X), axis=1)\n",
    "\n",
    "X = frame.values\n",
    "X_diff = X[X[:,10] == 1]\n",
    "X_same = X[X[:,10] == 0]\n",
    "X_same_train_len = int(len(X_diff) * 0.01)\n",
    "len(X_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里记下numpy.random.shuffle() 和np.random.permutation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 两者都是将数组进行打乱顺序\n",
    "- shuffle()是直接在原来数据上进行操作的，而permutation是返回的一个copy值，所以shuffle在处理大数据上更加快速\n",
    "- permutation 支持数值参数输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC 和 SVC的区别\n",
    "- linearSVC 使用的平方hinge loss,而SVC使用的是绝对hinge loss\n",
    "- linearSVC 是使用的是one-vs-rest方法，SVC使用的是one-vs-one\n",
    "- linearSVC 底层是liblinear 和 SVC使用的是libSVM\n",
    "- 在线性可分问题上，linearSVC比SVC更快\n",
    "- SVC的时间复杂度为O(n^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC参数解释\n",
    "- C: 目标函数的惩罚系数C，用来平衡分类间隔margin和错分样本的，default C = 1.0；\n",
    "- kernel：参数选择有RBF, Linear, Poly, Sigmoid, 默认的是\"RBF\";\n",
    "- degree：if you choose 'Poly' in param 2, this is effective, degree决定了多项式的最高次幂；\n",
    "- gamma：核函数的系数('Poly', 'RBF' and 'Sigmoid'), 默认是gamma = 1 / n_features;\n",
    "- coef0：核函数中的独立项，'RBF' and 'Poly'有效；\n",
    "- probablity: 可能性估计是否使用(true or false)；\n",
    "- shrinking：是否进行启发式；\n",
    "- tol（default = 1e - 3）: svm结束标准的精度;\n",
    "- cache_size: 制定训练所需要的内存（以MB为单位）；\n",
    "- class_weight: 每个类所占据的权重，不同的类设置不同的惩罚参数C, 缺省的话自适应；\n",
    "- verbose: 跟多线程有关，不大明白啥意思具体；\n",
    "- max_iter: 最大迭代次数，default = 1， if max_iter = -1, no limited;\n",
    "- decision_function_shape ： ‘ovo’ 一对一, ‘ovr’ 多对多  or None 无, default=None\n",
    "- random_state ：用于概率估计的数据重排时的伪随机数生成器的种子。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC\n",
    "- C：目标函数的惩罚系数C，用来平衡分类间隔margin和错分样本的，default C = 1.0；\n",
    "- loss ：指定损失函数,hinge or squared_hinge (default = squared_hinge)\n",
    "- penalty ：\n",
    "- dual ：选择算法来解决对偶或原始优化问题。当n_samples > n_features 时dual=false。\n",
    "- tol ：（default = 1e - 3）: svm结束标准的精度;\n",
    "- multi_class：如果y输出类别包含多类，用来确定多类策略， ovr表示一对多，“crammer_singer”优化所有类别的一个共同的目标\n",
    "- 如果选择“crammer_singer”，损失、惩罚和优化将会被被忽略。\n",
    "- fit_intercept ：\n",
    "- intercept_scaling ：\n",
    "- class_weight ：对于每一个类别i设置惩罚系数C = class_weight[i]*C,如果不给出，权重自动调整为 n_samples / (n_classes * np.bincount(y))\n",
    "- verbose：跟多线程有关，不大明白啥意思具体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for i in range(10):\n",
    "    np.random.shuffle(X_same)\n",
    "    train_data = np.concatenate((X_diff,X_same[-X_same_train_len:]))\n",
    "#     print(Counter(train_data[:,0]))\n",
    "    w = np.ones(len(train_data))\n",
    "    test_data = X_same[:-X_same_train_len]\n",
    "    clf = LinearSVC(loss = 'hinge',C = 500, class_weight = 'balanced')\n",
    "    clf.fit(train_data[:,1:],train_data[:,0])\n",
    "    score_list.append(score_err(clf,test_data[:,1:],test_data[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- class_weight 参数是为了解决样本不均衡的问题的\n",
    "- 可以为dict或者是'balanced',如果是balance的话，计算公式\n",
    "$$C_{0}=\\frac{n}{2*(n-m)} \\\\ C_{1} = \\frac{n}{2*m}$$\n",
    "其中n为总的样本数量，m为类别为1的样本数量\n",
    "- 样例越多，数值越小，惩罚的越小，关注的越小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16512968299711814"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion\n",
    "- 自己试验的结果是0.13 - 0.17 受shuffle的影响,而试验中的结果是0.127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TradaBoost](img\\tradaboost.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adaboost (SVM)\n",
    "class TrAdaBoost(object):\n",
    "    def __init__(self,max_iterator):\n",
    "        self.max_iterator = max_iterator\n",
    "    def learner(self):\n",
    "        clf = LinearSVC(C = 3000,class_weight = 'balanced')\n",
    "        return clf\n",
    "    def fit(self,train_diff,train_same,target_diff,target_same):\n",
    "        self.w = np.random.random(len(train_diff) + len(train_same))\n",
    "        n, m = len(train_diff),len(train_same)\n",
    "        self.beta = []\n",
    "        self.clf = []\n",
    "        for iter in range(self.max_iterator):\n",
    "            print('iterator : ', iter)\n",
    "            self.p = self.w / np.sum(self.w)\n",
    "            train_data = np.concatenate((train_diff,train_same))\n",
    "            target = np.concatenate((target_diff,target_same))\n",
    "            clf = self.learner()\n",
    "            clf.fit(train_data,target,sample_weight = self.p)\n",
    "            pred_train_same = clf.predict(train_same)\n",
    "            pred_train_diff = clf.predict(train_diff)\n",
    "            xi = np.sum(self.w[n:] * abs(pred_train_same - target_same)) / np.sum(self.w[n:])\n",
    "            if xi > 0.5:\n",
    "                self.max_iterator = iter\n",
    "                break\n",
    "            beta_t = xi / (1 - xi)\n",
    "            beta = 1 / (1 + np.sqrt(2 * np.log(n) / self.max_iterator))\n",
    "            self.w[:n] = self.w[:n] * np.power(beta, abs(pred_train_diff - target_diff))\n",
    "            self.w[n:] = self.w[n:] * np.power(beta_t, - abs(pred_train_same - target_same))\n",
    "            self.beta.append(beta_t)\n",
    "            self.clf.append(clf)\n",
    "    def predict(self,test):\n",
    "        up = int(np.ceil(self.max_iterator / 2))\n",
    "        result = []\n",
    "        for t in test: # \n",
    "            left = 1.0\n",
    "            right = 1.0\n",
    "            for i in np.arange(up - 1,self.max_iterator):\n",
    "#                 print(- self.clf[i].predict(np.array(t).reshape(1,-1)))\n",
    "                left *= np.power(self.beta[i],- self.clf[i].predict(np.array(t).reshape(1,-1))[0])\n",
    "                right *= np.power(self.beta[i], -1 / 2)\n",
    "            if left >= right:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "0.22737752161383284\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "0.14495677233429394\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "iterator :  3\n",
      "iterator :  4\n",
      "0.1979827089337176\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "0.13602305475504328\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "iterator :  3\n",
      "iterator :  4\n",
      "0.1475504322766571\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "0.1521613832853026\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "iterator :  3\n",
      "iterator :  4\n",
      "iterator :  5\n",
      "iterator :  6\n",
      "iterator :  7\n",
      "iterator :  8\n",
      "iterator :  9\n",
      "iterator :  10\n",
      "iterator :  11\n",
      "iterator :  12\n",
      "iterator :  13\n",
      "iterator :  14\n",
      "iterator :  15\n",
      "iterator :  16\n",
      "iterator :  17\n",
      "iterator :  18\n",
      "iterator :  19\n",
      "iterator :  20\n",
      "iterator :  21\n",
      "iterator :  22\n",
      "iterator :  23\n",
      "iterator :  24\n",
      "iterator :  25\n",
      "iterator :  26\n",
      "iterator :  27\n",
      "iterator :  28\n",
      "iterator :  29\n",
      "iterator :  30\n",
      "iterator :  31\n",
      "iterator :  32\n",
      "iterator :  33\n",
      "iterator :  34\n",
      "iterator :  35\n",
      "iterator :  36\n",
      "iterator :  37\n",
      "iterator :  38\n",
      "iterator :  39\n",
      "iterator :  40\n",
      "iterator :  41\n",
      "iterator :  42\n",
      "iterator :  43\n",
      "iterator :  44\n",
      "iterator :  45\n",
      "iterator :  46\n",
      "iterator :  47\n",
      "iterator :  48\n",
      "iterator :  49\n",
      "iterator :  50\n",
      "iterator :  51\n",
      "iterator :  52\n",
      "iterator :  53\n",
      "iterator :  54\n",
      "iterator :  55\n",
      "iterator :  56\n",
      "iterator :  57\n",
      "iterator :  58\n",
      "iterator :  59\n",
      "iterator :  60\n",
      "iterator :  61\n",
      "iterator :  62\n",
      "iterator :  63\n",
      "iterator :  64\n",
      "iterator :  65\n",
      "iterator :  66\n",
      "iterator :  67\n",
      "iterator :  68\n",
      "iterator :  69\n",
      "iterator :  70\n",
      "iterator :  71\n",
      "iterator :  72\n",
      "iterator :  73\n",
      "iterator :  74\n",
      "iterator :  75\n",
      "iterator :  76\n",
      "iterator :  77\n",
      "iterator :  78\n",
      "iterator :  79\n",
      "iterator :  80\n",
      "iterator :  81\n",
      "iterator :  82\n",
      "iterator :  83\n",
      "iterator :  84\n",
      "iterator :  85\n",
      "iterator :  86\n",
      "iterator :  87\n",
      "iterator :  88\n",
      "iterator :  89\n",
      "iterator :  90\n",
      "iterator :  91\n",
      "iterator :  92\n",
      "iterator :  93\n",
      "iterator :  94\n",
      "iterator :  95\n",
      "iterator :  96\n",
      "iterator :  97\n",
      "iterator :  98\n",
      "iterator :  99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/icdi/Desktop/py_ws/venv/lib/python3.5/site-packages/ipykernel_launcher.py:40: RuntimeWarning: divide by zero encountered in power\n",
      "/Users/icdi/Desktop/py_ws/venv/lib/python3.5/site-packages/ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in power\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09106628242074932\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "0.18789625360230544\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "iterator :  3\n",
      "iterator :  4\n",
      "iterator :  5\n",
      "iterator :  6\n",
      "iterator :  7\n",
      "iterator :  8\n",
      "iterator :  9\n",
      "iterator :  10\n",
      "iterator :  11\n",
      "iterator :  12\n",
      "iterator :  13\n",
      "iterator :  14\n",
      "iterator :  15\n",
      "iterator :  16\n",
      "iterator :  17\n",
      "iterator :  18\n",
      "iterator :  19\n",
      "iterator :  20\n",
      "iterator :  21\n",
      "iterator :  22\n",
      "iterator :  23\n",
      "iterator :  24\n",
      "iterator :  25\n",
      "iterator :  26\n",
      "iterator :  27\n",
      "iterator :  28\n",
      "iterator :  29\n",
      "iterator :  30\n",
      "iterator :  31\n",
      "iterator :  32\n",
      "iterator :  33\n",
      "iterator :  34\n",
      "iterator :  35\n",
      "iterator :  36\n",
      "iterator :  37\n",
      "iterator :  38\n",
      "iterator :  39\n",
      "iterator :  40\n",
      "iterator :  41\n",
      "iterator :  42\n",
      "iterator :  43\n",
      "iterator :  44\n",
      "iterator :  45\n",
      "iterator :  46\n",
      "iterator :  47\n",
      "iterator :  48\n",
      "iterator :  49\n",
      "iterator :  50\n",
      "iterator :  51\n",
      "iterator :  52\n",
      "iterator :  53\n",
      "iterator :  54\n",
      "iterator :  55\n",
      "iterator :  56\n",
      "iterator :  57\n",
      "iterator :  58\n",
      "iterator :  59\n",
      "iterator :  60\n",
      "iterator :  61\n",
      "iterator :  62\n",
      "iterator :  63\n",
      "iterator :  64\n",
      "iterator :  65\n",
      "iterator :  66\n",
      "iterator :  67\n",
      "iterator :  68\n",
      "iterator :  69\n",
      "iterator :  70\n",
      "iterator :  71\n",
      "iterator :  72\n",
      "iterator :  73\n",
      "iterator :  74\n",
      "iterator :  75\n",
      "iterator :  76\n",
      "iterator :  77\n",
      "iterator :  78\n",
      "iterator :  79\n",
      "iterator :  80\n",
      "iterator :  81\n",
      "iterator :  82\n",
      "iterator :  83\n",
      "iterator :  84\n",
      "iterator :  85\n",
      "iterator :  86\n",
      "iterator :  87\n",
      "iterator :  88\n",
      "iterator :  89\n",
      "iterator :  90\n",
      "iterator :  91\n",
      "iterator :  92\n",
      "iterator :  93\n",
      "iterator :  94\n",
      "iterator :  95\n",
      "iterator :  96\n",
      "iterator :  97\n",
      "iterator :  98\n",
      "iterator :  99\n",
      "0.1487031700288185\n",
      "iterator :  0\n",
      "iterator :  1\n",
      "iterator :  2\n",
      "iterator :  3\n",
      "iterator :  4\n",
      "iterator :  5\n",
      "iterator :  6\n",
      "iterator :  7\n",
      "iterator :  8\n",
      "iterator :  9\n",
      "iterator :  10\n",
      "iterator :  11\n",
      "iterator :  12\n",
      "iterator :  13\n",
      "iterator :  14\n",
      "iterator :  15\n",
      "iterator :  16\n",
      "iterator :  17\n",
      "iterator :  18\n",
      "iterator :  19\n",
      "iterator :  20\n",
      "iterator :  21\n",
      "iterator :  22\n",
      "iterator :  23\n",
      "iterator :  24\n",
      "iterator :  25\n",
      "iterator :  26\n",
      "0.1864553314121038\n"
     ]
    }
   ],
   "source": [
    "score_err = []\n",
    "for i in range(10):# 10次随机\n",
    "    np.random.shuffle(X_same)\n",
    "    trab = TrAdaBoost(max_iterator = 100)\n",
    "    trab.fit(X_diff[:,1:],X_same[-X_same_train_len:][:,1:],X_diff[:,0],X_same[-X_same_train_len:][:,0])\n",
    "    pred = trab.predict(test_data[:,1:])\n",
    "    err = 1 - np.mean(pred == test_data[:,0])\n",
    "    print(err)\n",
    "    score_err.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16201729106628243"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(score_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 本人做的是 0.15 - 0.22 ，论文中的数据是 0.071"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
