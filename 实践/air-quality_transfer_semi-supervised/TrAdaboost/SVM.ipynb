{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_rec_talk_mix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  1.])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits = 10, shuffle = True,random_state = 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7232, 67710)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for train_index,test_index in kfold.split(X):\n",
    "#     print((train_index).shape,(test_index).shape)\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    clf = SVC(kernel = 'linear')\n",
    "    clf.fit(X_train,y_train)\n",
    "    scores.append(score_acc(clf,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores # 这结果要比论文中的好多了吧，识别率100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性支持向量机最优化问题\n",
    "$$min_{w,b} \\frac{1}{2} ||w||^{2}\\\\ s.t. y_{i}(w*x_{i}+b)-1>=0,i=1,2,3,N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 凸优化问题\n",
    "$$min_{w} f(w) \\\\ s.t. g_{i}(x)<=0 \\\\ h_{i}(w) = 0$$\n",
    "- 其中，目标函数$f(w)$和约束函数$g_{i}(w)$都是$R_{n}$上的连续可微的凸函数，约束函数$h_{i}(w)$是$R^{n}$上的仿射函数\n",
    "- 仿射函数 $f(x)$为仿射函数,如果他满足$f(x)=ax+b,a\\in R^{n},b\\in R,x \\in R^{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学习的对偶算法\n",
    "- 应用拉格朗日对偶性，通过求解对偶问题得到原始问题的解\n",
    "- 对偶问题往往更加容易求解\n",
    "- 自然引入核函数，进而推广到非线性分类问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建拉格朗日函数\n",
    "$$L(w,b,a)=\\frac{1}{2}||w||^{2}-\\sum_{i=1}^N{\\alpha_{i}y_{i}(wx_{i}+b)}+\\sum_{i=1}^{N}{\\alpha_{i}}\\tag{1.1}$$\n",
    "- 是根据凸优化问题构建的\n",
    "- 原始问题求解的是$$min_{\\alpha}max_{w,b}L(w,b,\\alpha)$$ 只有在满足<b>约束条件</b>求最大值的时候才是原来的方程\n",
    "- 对偶问题$$max_{\\alpha}min_{w,b}L(w,b,\\alpha)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性可分求解过程\n",
    "- 将$\\alpha$看做是一个固定值，分别对$w$和$b$求导得到\n",
    "$$\\begin{eqnarray*}w =\\sum_{i=1}^{N}{\\alpha_{i}y_{i}x_{i}}\\tag{1.2}\\\\ \n",
    "\\sum_{i=1}^{N}{\\alpha_{i}y_{i}}=0\\tag{1.3} \\end{eqnarray*}$$\n",
    "- 将式1-2代入到1-1中得到\n",
    "$$min_{w,b}L(w,b,a)=-\\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}{\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}*x_{j})}+\\sum_{i=1}^{N}{\\alpha_{i}}$$\n",
    "- 对$min_{w,b}L(w,b,\\alpha)$对$\\alpha$的极大。即是\n",
    "$$max_{\\alpha}-\\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}{\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}*x_{j})}+\\sum_{i=1}^{N}{\\alpha_{i}} \\tag{1.4}\\\\ \n",
    "s.t. \\sum_{i=1}^{N}{\\alpha_{i}y_{i}}=0 \\\\\n",
    "\\alpha_{i}>=0\n",
    "$$\n",
    "- 式1.4的对偶问题为求最小值，然后使用SMO算法就可以求解$\\alpha$\n",
    "- 求出最优化的$\\alpha^{*}$之后，代入1.3求出$w$，找到一个$\\alpha_{j}>0$, \n",
    "$b^{*}=y_{j}-\\sum_{i=1}^{N}{\\alpha_{i}^{*}y_{i}(x_{i}x_{j})}$\n",
    "- 最后的求解函数为\n",
    "$$f(x)=sign(\\sum_{i=1}^{N}\\alpha_{i}y_{i}K(x,x_{i})+b^{*})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 软间隔最大化\n",
    "- 线性不可分意味着某些样本点$(x_{i},y_{i})$不能满足函数间隔大于等于1的约束条件。\n",
    "- 其原始问题为：\n",
    "$$min_{w,b,\\xi}\\frac{1}{2}||w||^{2}+C\\sum_{i=1}^{N}\\xi_{i}\\\\\n",
    "s.t. y_{i}(wx_{i}+b)>=1-\\xi_{i}, i =1,2,...,N \\\\\n",
    "\\xi_{i}>=0, i=1,2,...,N\n",
    "$$\n",
    "- 软间隔的支持向量$x_{i}$或者在间隔边界上，或者在间隔边界与分离超平面之间，或者在分离超平面误分一侧。若$\\alpha_{i}<C,则\\xi_{i}=0$,支持向量$x_{i}$恰好落在间隔边界上；若$\\alpha_{i}=C,0<\\xi_{i}<1$,则分类正确，$x_{i}$在间隔边界与分离超平面之间；若$\\alpha_{i}=C,\\xi_{i}=1$,则$x_{i}$在分离超平面上；若$\\alpha_{i}=C,\\xi_{i}>1$,则$x_{i}$位于分离超平面误分类一侧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 核函数\n",
    "- 设$\\chi$是输入空间，又称$H$为特征空间，如果存在一个从$\\chi$到$H$的映射\n",
    "$F(x):\\chi \\to H$使得对所有$x,z\\in \\chi$，函数$K(x,z)$满足条件$K(x,z)=F(x)F(z)$,则称$K(x,z)$为核函数，$F(x)$为映射函数\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正定核函数的判断？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 序列最小最优化算法SMO算法\n",
    "- 是用来求解1.4中的算法\n",
    "- 其是一种启发式算法，其基本思路是:如果两个变量的解都满足此优化问题的KTT条件，那么这个最优化问题的解就得到了。\n",
    "- 求解目标\n",
    "$$min_{\\alpha} \\frac{1}{2}\\sum_{i=1}^{N}\\sum_{j=1}^{N}{\\alpha_{i}\\alpha_{j}y_{i}y_{j}(x_{i}*x_{j})}-\\sum_{i=1}^{N}{\\alpha_{i}} \\tag{1.5}\\\\ \n",
    "s.t. \\sum_{i=1}^{N}{\\alpha_{i}y_{i}}=0 \\\\\n",
    "0=<\\alpha_{i}<=C\n",
    "$$\n",
    "- 当训练样本全部满足KKT条件，训练结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ICDI SVM\n",
    "class SVM(object):\n",
    "    def __init__(self,C = 1.0, eps = 1e-3, num_iterator = 1000):\n",
    "        self.C = C # 惩罚系数\n",
    "        self.eps = eps # 精度,用于判断准确度\n",
    "        self.b = 0\n",
    "        self.num_iterator = num_iterator\n",
    "    def kernel(self, x_i, x_j): # 默认使用的是线性核函数，即 F(x,y) = f(x)*f(y)\n",
    "        return np.dot(self.train[x_i],self.train[x_j].transpose())\n",
    "    \n",
    "    # 求得的是预测的值\n",
    "    def g(self,x_j):\n",
    "        sum = 0\n",
    "        for i,x_i in enumerate(self.train):\n",
    "            if self.cmp(self.alpha[i]) == 0: # 为零\n",
    "                continue\n",
    "            sum += self.alpha[i] * self.target[i] * self.kernel(i,x_j);\n",
    "        return sum + self.b\n",
    "    \n",
    "    # 求得是预测值和真实值之间的差值\n",
    "    def E_fun(self, x_i):\n",
    "        return self.g(x_i) - self.target[x_i]\n",
    "    \n",
    "    def cmp(self, x):\n",
    "        if abs(x) < self.eps:\n",
    "            return 0\n",
    "        if x > 0:\n",
    "            return 1\n",
    "        return -1;\n",
    "    \n",
    "    # 判断是否满足KTT 条件 ，这个地方写的很好\n",
    "    def _satisfy_KKT(self, i):\n",
    "        ygx = self.target[i] * self.g(i)\n",
    "        if abs(self.alpha[i])<self.eps:\n",
    "            return ygx > 1 or ygx == 1\n",
    "        elif abs(self.alpha[i]-self.C)<self.eps:\n",
    "            return ygx < 1 or ygx == 1\n",
    "        else:\n",
    "            return abs(ygx-1) < self.eps\n",
    "    \n",
    "    # 更新alpha值\n",
    "    def update_alpha(self,x_i, x_j): # i为2，j 为1\n",
    "        if self.target[x_i] != self.target[x_j]:\n",
    "            L = max(0,self.alpha[x_i] - self.alpha[x_j])\n",
    "            H = min(self.C,self.C + self.alpha[x_i] - self.alpha[x_j])\n",
    "        if self.target[x_i] == self.target[x_j]:\n",
    "            L = max(0,self.alpha[x_i] + self.alpha[x_j] - self.C)\n",
    "            H = min(self.C, self.alpha[x_i] + self.alpha[x_j])\n",
    "        alpha_x_i_old = self.alpha[x_i]\n",
    "        alpha_x_j_old = self.alpha[x_j]\n",
    "        \n",
    "        eta = self.kernel(x_i,x_i) + self.kernel(x_j,x_j) - 2 * self.kernel(x_i,x_j)\n",
    "       \n",
    "        self.alpha[x_i] = self.alpha[x_i] + self.target[x_i] * (self.E[x_j] - self.E[x_i]) / eta\n",
    "        if self.alpha[x_i] > H:\n",
    "            self.alpha[x_i] = H\n",
    "        elif self.alpha[x_i] < L:\n",
    "            self.alpha[x_i] = L\n",
    "        \n",
    "        self.alpha[x_j] = self.alpha[x_j] + self.target[x_i] * self.target[x_j] * (alpha_x_i_old - self.alpha[x_i]) \n",
    "        \n",
    "        \n",
    "        b1_new = - self.E[x_j] - self.target[x_j] * self.kernel(x_j,x_j) * (self.alpha[x_j] - alpha_x_j_old) - self.target[x_i] * self.kernel(x_i,x_j) * (self.alpha[x_i] - alpha_x_i_old) + self.b\n",
    "        b2_new = - self.E[x_i] - self.target[x_j] * self.kernel(x_i,x_j) * (self.alpha[x_j] - alpha_x_j_old) - self.target[x_i] * self.kernel(x_i,x_i) * (self.alpha[x_i] - alpha_x_i_old) + self.b\n",
    "       \n",
    "        if 0 < self.alpha[x_j] and self.alpha[x_j] < self.C:\n",
    "            self.b = b1_new\n",
    "        elif 0 < self.alpha[x_i] and self.alpha[x_i] < self.C:\n",
    "            self.b = b2_new\n",
    "        else:\n",
    "            self.b = (b1_new + b2_new ) / 2\n",
    "        self.E[x_i] = self.E_fun(x_i)\n",
    "        self.E[x_j] = self.E_fun(x_j)\n",
    "    \n",
    "    def choice_i_j(self):\n",
    "        # 直接找违反KTT 条件的值\n",
    "        index_list = [i for i in range(self.N)]\n",
    "\n",
    "        j1_list_1 = list(filter(lambda i: self.alpha[i] > 0 and self.alpha[i] < self.C, index_list))\n",
    "        j1_list_2 = list(set(index_list) - set(j1_list_1))\n",
    "\n",
    "        j1_list = j1_list_1\n",
    "        j1_list.extend(j1_list_2)\n",
    "\n",
    "        for j in j1_list:\n",
    "            if self._satisfy_KKT(j):\n",
    "                continue\n",
    "\n",
    "            E1 = self.E[j]\n",
    "            max_ = (0, 0)\n",
    "\n",
    "            for i in index_list:\n",
    "                if i == j:\n",
    "                    continue\n",
    "\n",
    "                E2 = self.E[i]\n",
    "                if abs(E1 - E2) > max_[0]:\n",
    "                    max_ = (abs(E1 - E2), i)\n",
    "\n",
    "            return j, max_[1]\n",
    "        return -1,-1\n",
    "    \n",
    "    def fit(self,X,Y):\n",
    "        self.alpha = np.zeros(X.shape[0]) # 初始化每一个参数\n",
    "        self.train = X\n",
    "        self.target = Y\n",
    "        self.N = X.shape[0]\n",
    "        self.E = np.array([self.E_fun(i) for i in range(self.N)])\n",
    "#         while(True):\n",
    "        for i in range(self.num_iterator):\n",
    "            print('iterator: ', i)\n",
    "            j,i = self.choice_i_j()\n",
    "            if i == -1 and j == -1:\n",
    "                break\n",
    "            self.update_alpha(i,j)\n",
    "    def predict(self,X):\n",
    "        result = []\n",
    "        for x in X:\n",
    "            sum = 0\n",
    "            for i,x_i in enumerate(self.train):\n",
    "                if self.cmp(self.alpha[i]) == 0: # 为零\n",
    "                    continue\n",
    "                sum += self.alpha[i] * self.target[i] * np.dot(x.transpose(),x_i);\n",
    "            result.append(self.cmp(sum + self.b))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_my = []\n",
    "for train_index,test_index in kfold.split(X):\n",
    "    X_train,X_test = X[train_index],X[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    clf = SVM()\n",
    "    clf.fit(X_train.toarray(),y_train)\n",
    "    score = score_acc(clf,X_test.toarray(),y_test)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
