{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Computer Hardware Data Set link http://archive.ics.uci.edu/ml/datasets/Computer+Hardware \n",
    "# related papaers 《learning with continuous vlaues》\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\" src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['vendor_name','model_name','myct','mmin','mmax','cach','chmin','chmax','prp','erp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.read_csv('./data/data.csv',header = None,names = names ,usecols = names[2:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = frame[names[2:-2]]\n",
    "y = frame[names[-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['myct', 'mmin', 'mmax', 'cach', 'chmin', 'chmax'], dtype='object')\n",
      "(209,)\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = names[2:]\n",
    "sd = np.std(frame['prp'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![选择属性的条件](img/error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 这里最大化 error\n",
    "- 和 CART 不同的是，CART使用的标准差或者偏差"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先回顾一下线性回归\n",
    "- 二元线性回归使用最小二乘法来算损失函数,得到参数的值为\n",
    "$$\\begin{split}\n",
    "a &= \\frac{\\sum_{i}^{m}{x_{i}y_{i}-m\\bar{x}\\bar{y}}}{\\sum_{i}^{m}x_{i}^{2}-m\\bar{x}^{2}} \\\\ \n",
    "b &= \\bar{y} - a\\bar{x}\n",
    "\\end{split}\n",
    "$$\n",
    "- 评判标准\n",
    "    * 均方误差(MSE)\n",
    "        ![mse](img\\mse.png)\n",
    "    * 根均方误差(RMSE),其是均方误差的开方\n",
    "    * 平均绝对误差(MAE)\n",
    "        ![mae](img\\mae.png)\n",
    "    * R-square \n",
    "        ![r-square](img\\R-square.png)\n",
    "- 多元线性回归求解\n",
    "    * 可以使用矩阵求导一步求得\n",
    "        ![multivariate_linear_model](img\\multivariate_linear_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M5 model tree 特点\n",
    "- 在每一个点使用标准回归技术建立一个多元回归模型\n",
    "- 使用(n+v)/(n-v)进行模型的平均残差进行修正。n是训练，v是模型参数的个数\n",
    "- 在每个叶子节点对线性模型进行简化，此处使用的是贪心的方法。(此处使用的是测试集)\n",
    "- 对每一个非节点进行剪枝判断，根据评估误差，来决定该节点的子节点是一个叶子还是不变(后剪枝)。\n",
    "- 对模型预测到的值进行从叶子往上进行一个平滑( 这个应该是对未知数据的)\n",
    "    * 平滑方程\n",
    "        ![smooth_function](img\\smooth.png)\n",
    "        其中PV($S_{i}$)是在$S_{i}$处的预测值$n_{i}$是包含的测试数据总数。\n",
    "        \n",
    "- 使用(1) relative error来做为而性能的比较，就是1 - $R^2$ (2) correlation 是指预测值和真实值的相关性 (3) 是percentage deviation 残差和目标比值的平均(不适用于目标为0的情况)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 先使用决策树看一下效果\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义分数值\n",
    "def score_func(reg, X, y):\n",
    "    pred_y = reg.predict(X)\n",
    "    # 这里应该是取绝对值\n",
    "    return np.mean(abs(y - pred_y) / y) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 1 - R^2 作为\n",
    "# relative_error\n",
    "def re(reg, X, y):\n",
    "    pred_y = reg.predict(X)\n",
    "    return np.sum((pred_y - y)**2) / np.sum((np.mean(y) - y)**2) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle = True,random_state = 0) # \n",
    "# shuffle 决定划分前是否进行洗牌，而random_state决定划分是否一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_cart = []\n",
    "for train_index,test_index in kfold.split(X):\n",
    "#     print((train_index).shape,(test_index).shape)\n",
    "    X_train,X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    regressor = DecisionTreeRegressor(criterion = 'mse',max_depth = 4)\n",
    "    regressor.fit(X_train,y_train)\n",
    "    scores_cart.append(re(regressor,X_test,y_test))\n",
    "#     scores_cart.append(score_func(regressor,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.747008134245207"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(scores_cart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性回归的效果\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy.linalg import *\n",
    "\n",
    "# score = cross_val_score(lr,X,y,scoring = score_func,cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "scores_lr = []\n",
    "for train_index,test_index in kfold.split(X):\n",
    "#     print((train_index).shape,(test_index).shape)\n",
    "    X_train,X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    lr.fit(X_train,y_train)\n",
    "    scores_lr.append(re(lr,X_test,y_test))\n",
    "#     scores_lr.append(score_func(lr,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.285910530311411"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(scores_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just try\n",
    "# 只用深度来进行预剪枝，只在叶子中训练一个多元线性模型，不进行后剪枝，而且没有对模型进行属性选择，不对其进行平滑，不进行残差修正\n",
    "class Node(object):\n",
    "    def __init__(self,w,split_feature,split_value,is_leaf):\n",
    "        self.w = None\n",
    "        self.split_index = split_feature # 划分特征的所以\n",
    "        self.split_value = split_value # 划分值\n",
    "        self.lef = None\n",
    "        self.rig = None\n",
    "        self.is_leaf = is_leaf\n",
    "    def set(self,is_leaf,w):\n",
    "        self.is_leaf = is_leaf\n",
    "        self.w = w\n",
    "        \n",
    "class simpleM5(object):\n",
    "    def __init__(self,max_depth):\n",
    "        self.max_depth = max_depth\n",
    "    def fit(self,train_data,train_label):\n",
    "        self.n = train_data.shape[0]\n",
    "        self.m = train_data.shape[1]\n",
    "        self.attri = np.array(range(train_data.shape[1]))\n",
    "        self.root = self._build_tree(0,train_data.values,train_label.values)\n",
    "    def _build_tree(self, dep,data,label): #（np.ndarrays,np.ndarrays) \n",
    "        # 在该层确定划分的属性索引，还有属性值\n",
    "        if(dep > self.max_depth):\n",
    "            return None # 当达到最大深度时返回\n",
    "        # 计算train_label的标准差，找到使得切分后，左右子空间标准差的期望 最小的最佳切分点\n",
    "        mi_index = -1;\n",
    "        mi_value = 1e9\n",
    "        mi_index_value = -1\n",
    "        for col in self.attri:\n",
    "            data_col = data[:,col]\n",
    "            sort_index = np.argsort(data_col)\n",
    "            data_col_sort = data_col[sort_index]\n",
    "            label_sort = label[sort_index]\n",
    "            for value in (np.unique(data_col_sort)):\n",
    "                index = data_col_sort < value\n",
    "                less_data = data_col_sort[index]\n",
    "                less_label = label_sort[index]\n",
    "                tmp = len(less_data) / self.n * np.std(less_label)\n",
    "                \n",
    "                index = data_col_sort >= value\n",
    "                more_data = data_col_sort[index]\n",
    "                more_label = label_sort[index]\n",
    "                tmp += len(more_label) / self.n * np.std(more_label)\n",
    "                if(tmp < mi_value):\n",
    "                    mi_value = tmp\n",
    "                    mi_index = col\n",
    "                    mi_index_value = value\n",
    "        # 得到划分点，将数据集按照最佳划分点进行划分\n",
    "        node = Node(None,mi_index,mi_index_value,False)\n",
    "        index = data[:,mi_index] < mi_index_value\n",
    "        left_data = data[index]\n",
    "        left_label = label[index]\n",
    "        index = data[:,mi_index] >= mi_index_value\n",
    "        right_data = data[index]\n",
    "        right_label = label[index]\n",
    "        tmp = dep + 1\n",
    "        node.left = self._build_tree(tmp,left_data,left_label)\n",
    "        node.right = self._build_tree(tmp, right_data,right_label)\n",
    "        if node.left == None and node.right == None: # 是叶子节点\n",
    "            inv_data = \n",
    "            oneStepTheta = np.dot(np.dot(inv(np.dot(X2.transpose(), X2)), X2.transpose()), Y)\n",
    "            data = data + np.diag(np.ones(()))\n",
    "            node.set(True,lr) # 一步算法多元回归的的参数\n",
    "        return node\n",
    "    def predict(self,test):\n",
    "        result = []\n",
    "        root = self.root\n",
    "        for t in test.values:\n",
    "           result.append(self._dfs(root,t)[0])\n",
    "        return np.array(result)\n",
    "\n",
    "    def _dfs(self,root,test):\n",
    "#         print(root.is_leaf)\n",
    "        if root.is_leaf:\n",
    "            return root.w.predict(test.reshape(1,-1))\n",
    "        if test[root.split_index] < root.split_value:\n",
    "            return self._dfs(root.left,test)\n",
    "        else:\n",
    "            return self._dfs(root.right,test) #important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/icdi/Desktop/py_ws/venv/lib/python3.5/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/icdi/Desktop/py_ws/venv/lib/python3.5/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/icdi/Desktop/py_ws/venv/lib/python3.5/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "scores_m5 = []\n",
    "for train_index,test_index in kfold.split(X):\n",
    "#     print((train_index).shape,(test_index).shape)\n",
    "    X_train,X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    m5 = simpleM5(max_depth = 3)\n",
    "    m5.fit(X_train, y_train)\n",
    "    scores_m5.append(re(m5,X_test,y_test))\n",
    "#     scores_m5.append(score_func(m5,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0947273192690123"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(scores_m5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_xgb = []\n",
    "for train_index,test_index in kfold.split(X):\n",
    "#     print((train_index).shape,(test_index).shape)\n",
    "    X_train,X_test = X.iloc[train_index],X.iloc[test_index]\n",
    "    y_train,y_test = y[train_index],y[test_index]\n",
    "    xgb_model = xgb.XGBRegressor(objective=\"reg:linear\", random_state=0)\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    scores_xgb.append(re(xgb_model,X_test,y_test))\n",
    "#     scores_m5.append(score_func(m5,X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.264912466167563"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(scores_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion(针对Computer_HardWare)\n",
    "- 使用不同的评判标准时产生的结论是不一样的，比如当使用平均绝对误差时，决策树回归最好，但是当使用relative error 时，Model 树表现最好。\n",
    "- 模型树在指标上都是比普通的回归要好，因为Model树可以能加关注局部线性，这点还是可以肯定的，但是模型树和决策树到底哪个好，就不知道了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
